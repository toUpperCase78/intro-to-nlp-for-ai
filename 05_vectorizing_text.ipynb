{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1df0d7c-5ff2-4160-a170-23930469bbb0",
   "metadata": {},
   "source": [
    "# Intro to NLP for AI | 05 - Vectorizing Text\n",
    "\n",
    "## Bag of Words\n",
    "\n",
    "In NLP, text data needs to be converted into numbers so that machine learning algorithms can understand it. One common method to do is Bag of Words (BoW) model. It turns text like sentence, paragraph or document into a collection of words and counts how often each word appears but ignoring the order of the words. It does not consider the order of the words or their grammar but focuses on counting how often each words appears in the text. This makes it useful for tasks like text classification, sentiment analysis and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3a9bdbb-6dc5-4fdb-adf3-97fde5fc48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e46ebc1-8853-42fb-bd41-98d0c163784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' Most shark attacks occur about 10 feet from the beach since that is where the people are',\n",
    "        'the efficiency with which he paired the socks in the drawer was quite admirable',\n",
    "        'carol drank the blood as if she were a vampire',\n",
    "        'giving directions that the mountains are to the west only works when you can see them',\n",
    "        'the sign said there was road work ahead so he decided to speed up',\n",
    "        'the gruff old man sat in the back of the bait shop grumbling to himself as he scooped out a handful of worms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd30d0ed-b10e-4572-a878-cc5793d9d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer()\n",
    "# countvec = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b1833c1-e415-42a7-bf09-53621d078e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec_fit = countvec.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26506d6-e639-47db-89de-c93d57b66384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvec_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e0748ec-3020-4741-9ef7-6ac0764b5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(countvec_fit.toarray(), columns=countvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "482e4112-9128-473f-8dd1-9d1531bae619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>about</th>\n",
       "      <th>admirable</th>\n",
       "      <th>ahead</th>\n",
       "      <th>are</th>\n",
       "      <th>as</th>\n",
       "      <th>attacks</th>\n",
       "      <th>back</th>\n",
       "      <th>bait</th>\n",
       "      <th>beach</th>\n",
       "      <th>...</th>\n",
       "      <th>were</th>\n",
       "      <th>west</th>\n",
       "      <th>when</th>\n",
       "      <th>where</th>\n",
       "      <th>which</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>works</th>\n",
       "      <th>worms</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  about  admirable  ahead  are  as  attacks  back  bait  beach  ...  \\\n",
       "0   1      1          0      0    1   0        1     0     0      1  ...   \n",
       "1   0      0          1      0    0   0        0     0     0      0  ...   \n",
       "2   0      0          0      0    0   1        0     0     0      0  ...   \n",
       "3   0      0          0      0    1   0        0     0     0      0  ...   \n",
       "4   0      0          0      1    0   0        0     0     0      0  ...   \n",
       "5   0      0          0      0    0   1        0     1     1      0  ...   \n",
       "\n",
       "   were  west  when  where  which  with  work  works  worms  you  \n",
       "0     0     0     0      1      0     0     0      0      0    0  \n",
       "1     0     0     0      0      1     1     0      0      0    0  \n",
       "2     1     0     0      0      0     0     0      0      0    0  \n",
       "3     0     1     1      0      0     0     0      1      0    1  \n",
       "4     0     0     0      0      0     0     1      0      0    0  \n",
       "5     0     0     0      0      0     0     0      0      1    0  \n",
       "\n",
       "[6 rows x 71 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1d9ad-2225-4d64-a772-62e80c4422e5",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency) is a statistical method used in NLP and information retrieval to evaluate how important a word is to a document in relation to a larger collection of documents. TF-IDF combines two components:\n",
    "\n",
    "1. **Term Frequency (TF):** Measures how often a word appears in a document. A higher frequency suggests greater importance. If a term appears frequently in a document, it is likely relevant to the document's content.\n",
    "\n",
    "`TF(t, d)` = (# of times term t appears in document d) / (Total # of terms in document d)\n",
    "\n",
    "2. **Inverse Document Frequency (IDF):** Reduces the weights of common words across multiple documents while increasing the weight of rare words. If a term appears in fewer documents, it is more likely to be meaningful and specific.\n",
    "\n",
    "`IDF(t, D)` = log(Total # of documents in corpus D / # of documents containing term t)\n",
    "\n",
    "This balance allows TF-IDF to highlight terms that are both frequenct within a specific document and distinctive across the text document, making it a useful tool for tasks like search ranking, text classification and keyword extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5950a252-1962-4b40-80d1-c08aad11fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43bfc1bb-99a2-4b81-9307-922ac2d00b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb79d87-ce9b-451d-be35-2ec01290c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvec_fit = tfidfvec.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a742e23-9d90-466f-8369-de403f667c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidfvec_fit.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c79f134e-6d60-4297-88f8-3da73afed2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bag = pd.DataFrame(tfidfvec_fit.toarray(), columns=tfidfvec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "712e8089-a3fb-472d-a964-482b83995bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10     about  admirable     ahead       are        as   attacks  \\\n",
      "0  0.257061  0.257061   0.000000  0.000000  0.210794  0.000000  0.257061   \n",
      "1  0.000000  0.000000   0.293641  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.000000  0.000000   0.000000  0.000000  0.000000  0.292313  0.000000   \n",
      "3  0.000000  0.000000   0.000000  0.000000  0.222257  0.000000  0.000000   \n",
      "4  0.000000  0.000000   0.000000  0.290766  0.000000  0.000000  0.000000   \n",
      "5  0.000000  0.000000   0.000000  0.000000  0.000000  0.178615  0.000000   \n",
      "\n",
      "      back     bait     beach  ...      were     west     when     where  \\\n",
      "0  0.00000  0.00000  0.257061  ...  0.000000  0.00000  0.00000  0.257061   \n",
      "1  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "2  0.00000  0.00000  0.000000  ...  0.356474  0.00000  0.00000  0.000000   \n",
      "3  0.00000  0.00000  0.000000  ...  0.000000  0.27104  0.27104  0.000000   \n",
      "4  0.00000  0.00000  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "5  0.21782  0.21782  0.000000  ...  0.000000  0.00000  0.00000  0.000000   \n",
      "\n",
      "      which      with      work    works    worms      you  \n",
      "0  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "1  0.293641  0.293641  0.000000  0.00000  0.00000  0.00000  \n",
      "2  0.000000  0.000000  0.000000  0.00000  0.00000  0.00000  \n",
      "3  0.000000  0.000000  0.000000  0.27104  0.00000  0.27104  \n",
      "4  0.000000  0.000000  0.290766  0.00000  0.00000  0.00000  \n",
      "5  0.000000  0.000000  0.000000  0.00000  0.21782  0.00000  \n",
      "\n",
      "[6 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bde441-d596-4e65-bc6e-7f91852f109f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
